{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ultimate guide to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `torch.Tensor` class and constructors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most important class in PyTorch. `torch.Tensor` is a \"multi-dimensional matrix\" (really in physics language it is just a multi-index tensor). There are multiple ways to create an object of `torch.Tensor` type. The most common one is `torch.tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# To create a tensor from a python array\n",
    "print(torch.tensor([1,2,3]))\n",
    "\n",
    "# You can also use multidimensional arrays \n",
    "print(torch.tensor([[1,2,3],[4,5,6]]))\n",
    "\n",
    "# It also accepts np.array\n",
    "print(torch.tensor(np.array([1,2,3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also special functions to create `torch.Tensor`s. The most useful ones are - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "tensor([[[-3.8644e-02,  4.0232e-01, -3.0686e-02, -1.2465e+00, -1.5573e+00,\n",
      "          -1.4558e+00],\n",
      "         [-6.3799e-02,  2.4106e+00,  6.4983e-01,  4.6104e-01,  2.6534e-01,\n",
      "           1.3786e+00]],\n",
      "\n",
      "        [[ 2.5173e-01,  3.4017e-01, -8.7414e-01, -1.7827e+00,  3.3580e-01,\n",
      "          -1.0868e+00],\n",
      "         [ 1.6930e-03,  1.3603e+00,  6.0495e-01,  6.1020e-01, -1.7526e-01,\n",
      "          -2.3597e-01]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 5 by 5 tensor filled with zeroes\n",
    "print(torch.zeros((5,5)))\n",
    "\n",
    "# Create a 3 by 5 tensor filled with ones\n",
    "print(torch.ones((3,5)))\n",
    "\n",
    "# Create a random 2 by 2 by 6 tensor from a Gaussian\n",
    "print(torch.randn((2,2,6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, all the tensors are created with `requires_grad` set to `False`. If you want to do any calculations involving gradients, this needs to be set to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "torchTensor.requires_grad = False\n",
      "torchTensor.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "# Tensor without grad\n",
    "print(torch.ones((2,2)).requires_grad)\n",
    "\n",
    "# Tensor with grad\n",
    "print(torch.ones((2,2), requires_grad=True).requires_grad)\n",
    "\n",
    "# You can also set the grad to be true later by using requires_grad_()\n",
    "torchTensor = torch.randn((2,2))\n",
    "print(f\"{torchTensor.requires_grad = }\")\n",
    "torchTensor.requires_grad_()\n",
    "print(f\"{torchTensor.requires_grad = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to access the data stored in `torch.Tensor`. They are `.item` and `.data`. `item` is used *only* when the tensor stores a scalar. `data` is used in general to access the data (and ignore other attributes like `grad` which we will see later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7446, -0.4623],\n",
      "        [-1.4433,  1.0537]])\n",
      "Error occurred: a Tensor with 4 elements cannot be converted to Scalar\n",
      "torchScalar.item() = 2\n"
     ]
    }
   ],
   "source": [
    "torchTensor = torch.randn((2,2))\n",
    "print(torchTensor.data)\n",
    "try:\n",
    "    print(torchTensor.item())\n",
    "except RuntimeError as error:\n",
    "    print(f\"Error occurred: {error}\")\n",
    "\n",
    "torchScalar = torch.tensor(2)\n",
    "try:\n",
    "    print(f\"{torchScalar.item() = }\")\n",
    "except RuntimeError as error:\n",
    "    print(f\"Error occurred: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on `torch.Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Torch` class comes with a huge set of operations on tensors. We will split the most important ones into unary and binary operators. Further, unary will be split into tensor operations and tensor functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unary tensor operators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.Tensor` has a bunch of standard operations such as transpose and Hermitian conjugation in the case of two-dimensional tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = tensor([[ 0.6264, -0.6803,  1.3870],\n",
      "        [-0.3869,  2.3262,  0.2047],\n",
      "        [-0.4378, -0.1837, -0.2527]])\n",
      "M.T = tensor([[ 0.6264, -0.3869, -0.4378],\n",
      "        [-0.6803,  2.3262, -0.1837],\n",
      "        [ 1.3870,  0.2047, -0.2527]])\n",
      "M.H = tensor([[ 0.6264, -0.3869, -0.4378],\n",
      "        [-0.6803,  2.3262, -0.1837],\n",
      "        [ 1.3870,  0.2047, -0.2527]])\n"
     ]
    }
   ],
   "source": [
    "# Trial tensor\n",
    "M = torch.randn((3,3))\n",
    "print(f\"{M = }\")\n",
    "\n",
    "# Transpose\n",
    "print(f\"{M.T = }\")\n",
    "\n",
    "# Hermitian conjugate (which would give the same result as T since M is real)\n",
    "print(f\"{M.H = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The situation with higher dimensional tensors is tricky. First there is `mT` which implements transpose in the trailing two dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = tensor([[[-1.4673, -0.4204, -1.1857],\n",
      "         [-0.3308, -0.0802,  0.0118],\n",
      "         [-0.8805, -0.0644, -0.2816]],\n",
      "\n",
      "        [[-0.2144, -0.1880, -1.1302],\n",
      "         [ 0.3032,  0.0827,  0.1062],\n",
      "         [-0.5461,  0.3554,  0.6406]],\n",
      "\n",
      "        [[ 0.0679, -0.3958,  0.1948],\n",
      "         [ 0.3312,  0.9028,  1.2418],\n",
      "         [ 0.5943,  0.6860, -0.3712]]])\n",
      "M.mT = tensor([[[-1.4673, -0.3308, -0.8805],\n",
      "         [-0.4204, -0.0802, -0.0644],\n",
      "         [-1.1857,  0.0118, -0.2816]],\n",
      "\n",
      "        [[-0.2144,  0.3032, -0.5461],\n",
      "         [-0.1880,  0.0827,  0.3554],\n",
      "         [-1.1302,  0.1062,  0.6406]],\n",
      "\n",
      "        [[ 0.0679,  0.3312,  0.5943],\n",
      "         [-0.3958,  0.9028,  0.6860],\n",
      "         [ 0.1948,  1.2418, -0.3712]]])\n",
      "M.mH = tensor([[[-1.4673, -0.3308, -0.8805],\n",
      "         [-0.4204, -0.0802, -0.0644],\n",
      "         [-1.1857,  0.0118, -0.2816]],\n",
      "\n",
      "        [[-0.2144,  0.3032, -0.5461],\n",
      "         [-0.1880,  0.0827,  0.3554],\n",
      "         [-1.1302,  0.1062,  0.6406]],\n",
      "\n",
      "        [[ 0.0679,  0.3312,  0.5943],\n",
      "         [-0.3958,  0.9028,  0.6860],\n",
      "         [ 0.1948,  1.2418, -0.3712]]])\n"
     ]
    }
   ],
   "source": [
    "# Trial tensor\n",
    "M = torch.randn((3,3,3))\n",
    "print(f\"{M = }\")\n",
    "\n",
    "# Transpose\n",
    "print(f\"{M.mT = }\")\n",
    "\n",
    "# Hermitian conjugate\n",
    "print(f\"{M.mH = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However in the case of `mH`, under the hood the function being used is `adjoint()` which transposes the last two dimensions and then conjugates. There is another available function called `.transpose()` which takes in two values (which indicate which dimensions to flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = tensor([[[-0.0152, -1.2074, -0.3261],\n",
      "         [-0.3511, -0.1746,  0.5307],\n",
      "         [-0.2593, -0.6867, -0.7115]],\n",
      "\n",
      "        [[ 1.2810, -1.6757,  0.5918],\n",
      "         [-0.2835,  0.0422,  1.0530],\n",
      "         [-1.2587, -0.9597, -1.8864]],\n",
      "\n",
      "        [[ 0.4300, -0.2072,  0.6119],\n",
      "         [-0.0768,  1.5598,  1.6492],\n",
      "         [-0.7949,  1.2559, -0.1922]]])\n",
      "M.mT = tensor([[[-0.0152, -0.3511, -0.2593],\n",
      "         [-1.2074, -0.1746, -0.6867],\n",
      "         [-0.3261,  0.5307, -0.7115]],\n",
      "\n",
      "        [[ 1.2810, -0.2835, -1.2587],\n",
      "         [-1.6757,  0.0422, -0.9597],\n",
      "         [ 0.5918,  1.0530, -1.8864]],\n",
      "\n",
      "        [[ 0.4300, -0.0768, -0.7949],\n",
      "         [-0.2072,  1.5598,  1.2559],\n",
      "         [ 0.6119,  1.6492, -0.1922]]])\n",
      "M.transpose(-1, -2) = tensor([[[-0.0152, -0.3511, -0.2593],\n",
      "         [-1.2074, -0.1746, -0.6867],\n",
      "         [-0.3261,  0.5307, -0.7115]],\n",
      "\n",
      "        [[ 1.2810, -0.2835, -1.2587],\n",
      "         [-1.6757,  0.0422, -0.9597],\n",
      "         [ 0.5918,  1.0530, -1.8864]],\n",
      "\n",
      "        [[ 0.4300, -0.0768, -0.7949],\n",
      "         [-0.2072,  1.5598,  1.2559],\n",
      "         [ 0.6119,  1.6492, -0.1922]]])\n"
     ]
    }
   ],
   "source": [
    "# Trial tensor\n",
    "M = torch.randn((3,3,3))\n",
    "print(f\"{M = }\")\n",
    "\n",
    "# Transpose\n",
    "print(f\"{M.mT = }\")\n",
    "\n",
    "# transpose() function\n",
    "print(f\"{M.transpose(-1, -2) = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more complicated permutations of the indices, one can use `permute()`. I am not writing that down since I don't envision it being useful at this moment. It will be good to revisit if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.Tensor` comes with a *_huge_* set of functions that can be applied to tensors. The most common ones are `exp()`, `log()` and `tanh()`. All of these come with an in-place version which is accessed by appending `_` to the function names. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the only important operator I can think of is `torch.matmul` which as the name suggests is matrix multiplication. It behaves in different ways depending on the dimensions of the objects being multiplied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.matmul(x,y) = tensor(29)\n",
      "torch.matmul(x,y) = tensor([ 71,  70, 107])\n",
      "torch.matmul(y,x) = tensor([ 80,  50, 110])\n",
      "torch.matmul(x,y) = tensor([[ 44,  33,  88],\n",
      "        [ 48,  36,  96],\n",
      "        [ 80,  60, 160]])\n"
     ]
    }
   ],
   "source": [
    "# Scalar product\n",
    "x = torch.tensor([1,3,2])\n",
    "y = torch.tensor([4,3,8])\n",
    "print(f\"{torch.matmul(x,y) = }\")\n",
    "\n",
    "# Linear transform\n",
    "x = torch.tensor([[3,1,7],[4,2,6],[7,5,8]])\n",
    "y = torch.tensor([4,3,8])\n",
    "print(f\"{torch.matmul(x,y) = }\")\n",
    "\n",
    "# Vector - matrix multiplication\n",
    "x = torch.tensor([[3,1,7],[4,2,6],[7,5,8]])\n",
    "y = torch.tensor([4,3,8])\n",
    "print(f\"{torch.matmul(y,x) = }\") # Here the way it is multiplied is [(4*3)+(3*4)+(8*7), (4*1)+(3*2)+(8*5), (4*7)+(3*6)+(8*8)]\n",
    "\n",
    "# matrix - matrix multiplication\n",
    "x = torch.tensor([[3,1,7],[4,2,6],[7,5,8]])\n",
    "y = torch.tensor([[4,3,8],[4,3,8],[4,3,8]])\n",
    "print(f\"{torch.matmul(x,y) = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note here that in the cases where the shapes of `x` and `y` are different, there is quite a bit of under-the-hood \"magic\" happening in terms of dimension broadcasting. I will document this a bit in the section below, but also in much more detail as a separate section because that is highly important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also use `@` instead of `torch.matmul()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x @ y = tensor(29)\n",
      "x @ y = tensor([ 71,  70, 107])\n",
      "y @ x = tensor([ 80,  50, 110])\n",
      "x @ y = tensor([[ 44,  33,  88],\n",
      "        [ 48,  36,  96],\n",
      "        [ 80,  60, 160]])\n"
     ]
    }
   ],
   "source": [
    "# Scalar product\n",
    "x = torch.tensor([1,3,2])\n",
    "y = torch.tensor([4,3,8])\n",
    "print(f\"{x @ y = }\")\n",
    "\n",
    "# Linear transform\n",
    "x = torch.tensor([[3,1,7],[4,2,6],[7,5,8]])\n",
    "y = torch.tensor([4,3,8])\n",
    "print(f\"{x @ y = }\")\n",
    "\n",
    "# Vector - matrix multiplication\n",
    "x = torch.tensor([[3,1,7],[4,2,6],[7,5,8]])\n",
    "y = torch.tensor([4,3,8])\n",
    "print(f\"{y @ x = }\") # Here the way it is multiplied is [(4*3)+(3*4)+(8*7), (4*1)+(3*2)+(8*5), (4*7)+(3*6)+(8*8)]\n",
    "\n",
    "# matrix - matrix multiplication\n",
    "x = torch.tensor([[3,1,7],[4,2,6],[7,5,8]])\n",
    "y = torch.tensor([[4,3,8],[4,3,8],[4,3,8]])\n",
    "print(f\"{x @ y = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutating operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I particularly want to document the behaviour of `sum` which is important since it can have weird behaviours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor dimension broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating gradients with backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
