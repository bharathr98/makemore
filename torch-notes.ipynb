{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ultimate guide to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `torch.Tensor` class and constructors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most important classes in PyTorch. `torch.Tensor` is a \"multi-dimensional matrix\" (really in physics language it is just a multi-index tensor). There are multiple ways to create an object of `torch.Tensor` type. The most common one is `torch.tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# To create a tensor from a python array\n",
    "print(torch.tensor([1,2,3]))\n",
    "\n",
    "# You can also use multidimensional arrays \n",
    "print(torch.tensor([[1,2,3],[4,5,6]]))\n",
    "\n",
    "# It also accepts np.array\n",
    "print(torch.tensor(np.array([1,2,3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also special functions to create `torch.Tensor`s. The most useful ones are - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "tensor([[[ 0.1815,  1.1265,  1.7042,  1.1012, -0.5984, -0.1766],\n",
      "         [-0.2570, -0.1536, -0.9602, -1.9536, -0.1074, -0.7823]],\n",
      "\n",
      "        [[-0.6211, -1.6089,  0.9538,  0.7135, -0.8947,  0.2069],\n",
      "         [ 0.8291, -0.6183, -0.6868,  1.3104, -1.3237,  1.1811]]])\n",
      "tensor([[[19, 16, 16, 15, 16, 18],\n",
      "         [17, 19, 16, 18, 17, 16]],\n",
      "\n",
      "        [[16, 18, 18, 17, 15, 15],\n",
      "         [17, 16, 15, 18, 18, 17]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 5 by 5 tensor filled with zeroes\n",
    "print(torch.zeros((5,5)))\n",
    "\n",
    "# Create a 3 by 5 tensor filled with ones\n",
    "print(torch.ones((3,5)))\n",
    "\n",
    "# Create a random 2 by 2 by 6 tensor from a Gaussian\n",
    "print(torch.randn((2,2,6)))\n",
    "\n",
    "# Create a random 2 by 2 by 6 tensor populated by integers\n",
    "# Syntax is int low, int high, tuple of sizes\n",
    "print(torch.randint(15, 20, (2,2,6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, all the tensors are created with `requires_grad` set to `False`. If you want to do any calculations involving gradients, this needs to be set to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "torchTensor.requires_grad = False\n",
      "torchTensor.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "# Tensor without grad\n",
    "print(torch.ones((2,2)).requires_grad)\n",
    "\n",
    "# Tensor with grad\n",
    "print(torch.ones((2,2), requires_grad=True).requires_grad)\n",
    "\n",
    "# You can also set the grad to be true later by using requires_grad_()\n",
    "torchTensor = torch.randn((2,2))\n",
    "print(f\"{torchTensor.requires_grad = }\")\n",
    "torchTensor.requires_grad_()\n",
    "print(f\"{torchTensor.requires_grad = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to access the data stored in `torch.Tensor`. They are `.item` and `.data`. `item` is used *only* when the tensor stores a scalar. `data` is used in general to access the data (and ignore other attributes like `grad` which we will see later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7446, -0.4623],\n",
      "        [-1.4433,  1.0537]])\n",
      "Error occurred: a Tensor with 4 elements cannot be converted to Scalar\n",
      "torchScalar.item() = 2\n"
     ]
    }
   ],
   "source": [
    "torchTensor = torch.randn((2,2))\n",
    "print(torchTensor.data)\n",
    "try:\n",
    "    print(torchTensor.item())\n",
    "except RuntimeError as error:\n",
    "    print(f\"Error occurred: {error}\")\n",
    "\n",
    "torchScalar = torch.tensor(2)\n",
    "try:\n",
    "    print(f\"{torchScalar.item() = }\")\n",
    "except RuntimeError as error:\n",
    "    print(f\"Error occurred: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also index into the tensor exactly the way you would index into a multidimensional array in classic Python. This can be powerful because now you can pick specific parts of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 48, 3])\n",
      "torch.Size([48, 3])\n",
      "torch.Size([7, 3])\n",
      "torch.Size([7, 3])\n",
      "torch.Size([7, 48])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([7, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "tensorToIndex = torch.randn((7,48,3))\n",
    "print(tensorToIndex.shape)\n",
    "\n",
    "# Accessing an element in the first dimension\n",
    "print(tensorToIndex[2].shape)\n",
    "\n",
    "# Accessing an element in the second dimension\n",
    "print(tensorToIndex[:,22,:].shape)\n",
    "print(tensorToIndex[:,22].shape)\n",
    "\n",
    "# Accessing an element in the third dimension\n",
    "print(tensorToIndex[:,:,2].shape)\n",
    "\n",
    "# We can build a new tensor by indexing the old tensor at specific values using a tensor\n",
    "indices = torch.tensor([[1,5,2],[2,0,0],[0,1,2]])\n",
    "print(indices.shape)\n",
    "print(tensorToIndex[:,indices,:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the above code does is the following. It tells PyTorch to keep the first and third dimension as it is, and inserts new dimensions between the first and the third dimension. The second dimension in `tensorToIndex`, which was 48 dimensional, now gets replaced by two dimensions of size [3,3] since the index tensor is of shape [3,3]. \n",
    "\n",
    "How does it populate the new dimensions? That information comes from the `index` tensor itself. For the specific example used above, `index` tells PyTorch that at position [-, 0, 0, -] it wants PyTorch to put [-, 1, -] from `tensorToIndex`. At [-, 1, 0, -] it wants [-, 2, -] from the old tensor, and so on.\n",
    "\n",
    "If we do not use any `:` and only pass `indices` directly, then it does the above operation on the left most dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 48, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3, 48, 3])\n"
     ]
    }
   ],
   "source": [
    "# We can build a new tensor by indexing the old tensor at specific values using a tensor\n",
    "indices = torch.tensor([[1,5,2],[2,0,0],[0,1,2]])\n",
    "print(tensorToIndex.shape)\n",
    "print(indices.shape)\n",
    "print(tensorToIndex[indices].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be particularly useful in situations like the following. Let's say I have `N = 5` classes. I have a dataset `X` that contain samples of these classes (for example, we could have `N = 26` and `X` is a letters that appear in my dataset). Normally, one would one-hot encode these classes into a N-dimensional vector and apply a linear transformation on it. However, one-hot encoding something and then multiplying with a matrix is equivalent to picking a specific row (or column depending on how you look at it). Thus we can just directly index into the tensor using `X`. See below for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.]])\n",
      "torch.Size([40, 5])\n",
      "torch.Size([40, 3])\n",
      "torch.Size([40, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"dataset\" with 40 samples\n",
    "X = torch.randint(5, (40,))\n",
    "\n",
    "# One-hot encoding\n",
    "Xenc = F.one_hot(X, num_classes=5).float()\n",
    "print(Xenc)\n",
    "print(Xenc.shape)\n",
    "\n",
    "matrix = torch.randn((5, 3))\n",
    "\n",
    "# Matrix multiply\n",
    "print((Xenc @ matrix).shape)\n",
    "\n",
    "# Index into the matrix\n",
    "print(matrix[X].shape)\n",
    "\n",
    "# Checking they are the same element-wise\n",
    "(Xenc @ matrix) == matrix[X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on `torch.Tensor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Torch` class comes with a huge set of operations on tensors. We will split the most important ones into unary and binary operators. Further, unary will be split into tensor operations and tensor functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unary tensor operators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.Tensor` has a bunch of standard operations such as transpose and Hermitian conjugation in the case of two-dimensional tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = tensor([[ 0.6264, -0.6803,  1.3870],\n",
      "        [-0.3869,  2.3262,  0.2047],\n",
      "        [-0.4378, -0.1837, -0.2527]])\n",
      "M.T = tensor([[ 0.6264, -0.3869, -0.4378],\n",
      "        [-0.6803,  2.3262, -0.1837],\n",
      "        [ 1.3870,  0.2047, -0.2527]])\n",
      "M.H = tensor([[ 0.6264, -0.3869, -0.4378],\n",
      "        [-0.6803,  2.3262, -0.1837],\n",
      "        [ 1.3870,  0.2047, -0.2527]])\n"
     ]
    }
   ],
   "source": [
    "# Trial tensor\n",
    "M = torch.randn((3,3))\n",
    "print(f\"{M = }\")\n",
    "\n",
    "# Transpose\n",
    "print(f\"{M.T = }\")\n",
    "\n",
    "# Hermitian conjugate (which would give the same result as T since M is real)\n",
    "print(f\"{M.H = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The situation with higher dimensional tensors is tricky. First there is `mT` which implements transpose in the trailing two dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = tensor([[[-1.4673, -0.4204, -1.1857],\n",
      "         [-0.3308, -0.0802,  0.0118],\n",
      "         [-0.8805, -0.0644, -0.2816]],\n",
      "\n",
      "        [[-0.2144, -0.1880, -1.1302],\n",
      "         [ 0.3032,  0.0827,  0.1062],\n",
      "         [-0.5461,  0.3554,  0.6406]],\n",
      "\n",
      "        [[ 0.0679, -0.3958,  0.1948],\n",
      "         [ 0.3312,  0.9028,  1.2418],\n",
      "         [ 0.5943,  0.6860, -0.3712]]])\n",
      "M.mT = tensor([[[-1.4673, -0.3308, -0.8805],\n",
      "         [-0.4204, -0.0802, -0.0644],\n",
      "         [-1.1857,  0.0118, -0.2816]],\n",
      "\n",
      "        [[-0.2144,  0.3032, -0.5461],\n",
      "         [-0.1880,  0.0827,  0.3554],\n",
      "         [-1.1302,  0.1062,  0.6406]],\n",
      "\n",
      "        [[ 0.0679,  0.3312,  0.5943],\n",
      "         [-0.3958,  0.9028,  0.6860],\n",
      "         [ 0.1948,  1.2418, -0.3712]]])\n",
      "M.mH = tensor([[[-1.4673, -0.3308, -0.8805],\n",
      "         [-0.4204, -0.0802, -0.0644],\n",
      "         [-1.1857,  0.0118, -0.2816]],\n",
      "\n",
      "        [[-0.2144,  0.3032, -0.5461],\n",
      "         [-0.1880,  0.0827,  0.3554],\n",
      "         [-1.1302,  0.1062,  0.6406]],\n",
      "\n",
      "        [[ 0.0679,  0.3312,  0.5943],\n",
      "         [-0.3958,  0.9028,  0.6860],\n",
      "         [ 0.1948,  1.2418, -0.3712]]])\n"
     ]
    }
   ],
   "source": [
    "# Trial tensor\n",
    "M = torch.randn((3,3,3))\n",
    "print(f\"{M = }\")\n",
    "\n",
    "# Transpose\n",
    "print(f\"{M.mT = }\")\n",
    "\n",
    "# Hermitian conjugate\n",
    "print(f\"{M.mH = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However in the case of `mH`, under the hood the function being used is `adjoint()` which transposes the last two dimensions and then conjugates. There is another available function called `.transpose()` which takes in two values (which indicate which dimensions to flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = tensor([[[-0.0152, -1.2074, -0.3261],\n",
      "         [-0.3511, -0.1746,  0.5307],\n",
      "         [-0.2593, -0.6867, -0.7115]],\n",
      "\n",
      "        [[ 1.2810, -1.6757,  0.5918],\n",
      "         [-0.2835,  0.0422,  1.0530],\n",
      "         [-1.2587, -0.9597, -1.8864]],\n",
      "\n",
      "        [[ 0.4300, -0.2072,  0.6119],\n",
      "         [-0.0768,  1.5598,  1.6492],\n",
      "         [-0.7949,  1.2559, -0.1922]]])\n",
      "M.mT = tensor([[[-0.0152, -0.3511, -0.2593],\n",
      "         [-1.2074, -0.1746, -0.6867],\n",
      "         [-0.3261,  0.5307, -0.7115]],\n",
      "\n",
      "        [[ 1.2810, -0.2835, -1.2587],\n",
      "         [-1.6757,  0.0422, -0.9597],\n",
      "         [ 0.5918,  1.0530, -1.8864]],\n",
      "\n",
      "        [[ 0.4300, -0.0768, -0.7949],\n",
      "         [-0.2072,  1.5598,  1.2559],\n",
      "         [ 0.6119,  1.6492, -0.1922]]])\n",
      "M.transpose(-1, -2) = tensor([[[-0.0152, -0.3511, -0.2593],\n",
      "         [-1.2074, -0.1746, -0.6867],\n",
      "         [-0.3261,  0.5307, -0.7115]],\n",
      "\n",
      "        [[ 1.2810, -0.2835, -1.2587],\n",
      "         [-1.6757,  0.0422, -0.9597],\n",
      "         [ 0.5918,  1.0530, -1.8864]],\n",
      "\n",
      "        [[ 0.4300, -0.0768, -0.7949],\n",
      "         [-0.2072,  1.5598,  1.2559],\n",
      "         [ 0.6119,  1.6492, -0.1922]]])\n"
     ]
    }
   ],
   "source": [
    "# Trial tensor\n",
    "M = torch.randn((3,3,3))\n",
    "print(f\"{M = }\")\n",
    "\n",
    "# Transpose\n",
    "print(f\"{M.mT = }\")\n",
    "\n",
    "# transpose() function\n",
    "print(f\"{M.transpose(-1, -2) = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more complicated permutations of the indices, one can use `permute()`. I am not writing that down since I don't envision it being useful at this moment. It will be good to revisit if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.Tensor` comes with a *_huge_* set of functions that can be applied to tensors. The most common ones are `exp()`, `log()` and `tanh()`. All of these come with an in-place version which is accessed by appending `_` to the function names. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the only important operator I can think of is `torch.matmul` which as the name suggests is matrix multiplication. It behaves in different ways depending on the dimensions of the objects being multiplied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.matmul(x,y) = tensor(29)\n",
      "torch.matmul(x,y) = tensor([ 71,  70, 107])\n",
      "torch.matmul(y,x) = tensor([ 80,  50, 110])\n",
      "torch.matmul(x,y) = tensor([[ 44,  33,  88],\n",
      "        [ 48,  36,  96],\n",
      "        [ 80,  60, 160]])\n"
     ]
    }
   ],
   "source": [
    "# Scalar product\n",
    "x = torch.tensor([1,3,2])\n",
    "y = torch.tensor([4,3,8])\n",
    "print(f\"{torch.matmul(x,y) = }\")\n",
    "\n",
    "# Linear transform\n",
    "x = torch.tensor([[3,1,7],[4,2,6],[7,5,8]])\n",
    "y = torch.tensor([4,3,8])\n",
    "print(f\"{torch.matmul(x,y) = }\")\n",
    "\n",
    "# Vector - matrix multiplication\n",
    "x = torch.tensor([[3,1,7],[4,2,6],[7,5,8]])\n",
    "y = torch.tensor([4,3,8])\n",
    "print(f\"{torch.matmul(y,x) = }\") # Here the way it is multiplied is [(4*3)+(3*4)+(8*7), (4*1)+(3*2)+(8*5), (4*7)+(3*6)+(8*8)]\n",
    "\n",
    "# matrix - matrix multiplication\n",
    "x = torch.tensor([[3,1,7],[4,2,6],[7,5,8]])\n",
    "y = torch.tensor([[4,3,8],[4,3,8],[4,3,8]])\n",
    "print(f\"{torch.matmul(x,y) = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note here that in the cases where the shapes of `x` and `y` are different, there is quite a bit of under-the-hood \"magic\" happening in terms of dimension broadcasting. I will document this a bit in the section below, but also in much more detail as a separate section because that is highly important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also use `@` instead of `torch.matmul()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x @ y = tensor(29)\n",
      "x @ y = tensor([ 71,  70, 107])\n",
      "y @ x = tensor([ 80,  50, 110])\n",
      "x @ y = tensor([[ 44,  33,  88],\n",
      "        [ 48,  36,  96],\n",
      "        [ 80,  60, 160]])\n"
     ]
    }
   ],
   "source": [
    "# Scalar product\n",
    "x = torch.tensor([1,3,2])\n",
    "y = torch.tensor([4,3,8])\n",
    "print(f\"{x @ y = }\")\n",
    "\n",
    "# Linear transform\n",
    "x = torch.tensor([[3,1,7],[4,2,6],[7,5,8]])\n",
    "y = torch.tensor([4,3,8])\n",
    "print(f\"{x @ y = }\")\n",
    "\n",
    "# Vector - matrix multiplication\n",
    "x = torch.tensor([[3,1,7],[4,2,6],[7,5,8]])\n",
    "y = torch.tensor([4,3,8])\n",
    "print(f\"{y @ x = }\") # Here the way it is multiplied is [(4*3)+(3*4)+(8*7), (4*1)+(3*2)+(8*5), (4*7)+(3*6)+(8*8)]\n",
    "\n",
    "# matrix - matrix multiplication\n",
    "x = torch.tensor([[3,1,7],[4,2,6],[7,5,8]])\n",
    "y = torch.tensor([[4,3,8],[4,3,8],[4,3,8]])\n",
    "print(f\"{x @ y = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations that mutate tensor dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I particularly want to document the behaviour of `sum` and the usage of `keepdims` which is important since it can have weird behaviours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also add `torch.cat`, `torch.unbind`, `torch.view`, and understand Eric Yang's Pytorch internal memory storage - http://blog.ezyang.com/2019/05/pytorch-internals/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor dimension broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating gradients with backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases it is as simple as setting the gradient to `None` (which is PyTorch's equivalent for zero gradient) and then use the `backward` method. Note that `backward` only works on functions that output a scalar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([[ 6.8919e-01,  5.9545e-01,  1.0578e+00,  6.5663e-01, -3.1901e-01,\n",
      "          2.5812e+00, -4.5603e-01, -1.8559e+00,  6.1421e-01, -1.4582e+00,\n",
      "         -1.1110e+00,  1.7701e-01,  4.1079e+00, -9.9751e-01, -8.9327e-01,\n",
      "          2.8381e-01, -2.9639e+00,  1.7887e+00,  2.7781e-01,  9.4487e-01],\n",
      "        [-4.0027e+00, -3.6812e+00, -2.9251e+00, -4.4314e+00, -5.9880e+00,\n",
      "          1.1277e+00, -5.1030e-01, -4.5243e-01, -1.6009e+00,  2.2205e+00,\n",
      "         -2.3395e+00, -1.3554e+00,  3.9091e+00,  3.7297e-01, -5.8702e-01,\n",
      "         -3.5751e-01,  1.5001e+00, -2.5243e-01,  1.8313e+00,  2.0883e+00],\n",
      "        [ 1.0277e-02,  2.7778e+00, -1.3754e+00, -2.6729e+00,  1.2703e+00,\n",
      "          4.0222e+00,  2.9275e+00, -1.1829e+00, -2.6049e-01, -6.0611e-01,\n",
      "          1.2003e+00, -2.9057e+00, -6.6012e-01,  1.9421e+00,  2.2600e-01,\n",
      "         -3.1704e+00,  3.6250e+00, -1.9206e+00, -3.1726e+00, -8.6204e-03],\n",
      "        [ 2.3642e-01, -3.1587e+00, -1.0306e+00,  2.0279e+00, -1.0325e+00,\n",
      "          1.1159e+00,  9.5901e-01, -4.0170e-01,  2.9299e+00, -2.6970e+00,\n",
      "         -2.7086e-02,  1.6151e+00,  8.6363e-01, -6.3241e-01, -2.5055e+00,\n",
      "          7.2963e-02, -4.1252e+00, -6.8770e-01, -1.2351e+00,  1.6136e+00],\n",
      "        [-9.3385e-01,  1.8540e+00,  3.4865e+00,  6.0925e-01, -5.8370e-01,\n",
      "          3.0228e+00, -8.7939e-01, -8.0702e-01,  9.8079e-01,  2.2071e+00,\n",
      "         -2.9562e+00,  9.3049e-01,  4.8898e+00, -2.0956e-01, -1.5440e-01,\n",
      "          3.0184e+00,  5.3607e-01,  1.3235e+00,  3.7695e-01, -4.2847e+00],\n",
      "        [-3.8838e-01, -1.7475e+00, -2.4177e+00,  8.9865e-01, -2.6114e+00,\n",
      "          1.0001e+00, -2.4562e+00, -3.4343e-01, -5.4404e-02, -1.3155e+00,\n",
      "          2.2617e+00, -1.1431e+00,  3.7186e+00,  8.5653e-01, -1.0393e+00,\n",
      "          1.7092e-01,  6.1446e-01, -2.8783e-01,  6.5775e-01,  1.4389e+00],\n",
      "        [ 1.8550e+00,  1.2983e+00, -6.5803e-01,  1.1276e+00, -1.3030e+00,\n",
      "          1.8401e+00, -2.0571e+00,  8.4082e-01, -2.6237e+00,  3.5166e-01,\n",
      "          1.6799e+00,  2.1556e+00,  3.6166e+00, -4.6870e+00,  1.3460e+00,\n",
      "          4.6869e-01,  8.9867e-01, -3.1024e+00,  1.1809e+00,  4.5565e+00],\n",
      "        [ 2.4552e+00, -8.7167e-01, -2.3227e+00, -9.7802e-01, -4.5370e+00,\n",
      "          3.9989e+00, -1.1812e+00,  1.2060e+00,  1.0789e+00, -3.9612e+00,\n",
      "          1.9151e-01, -6.5653e-01,  1.9508e+00, -2.7911e+00, -1.6148e+00,\n",
      "          7.2032e-01, -1.9342e+00, -3.6861e+00,  1.7411e+00,  3.8131e-01],\n",
      "        [-1.3210e+00,  5.0999e-01,  5.3533e-01,  8.1039e-01,  7.7793e-01,\n",
      "          1.0651e+00,  1.3009e+00, -1.1571e+00,  2.5800e+00, -1.6765e+00,\n",
      "         -7.2495e-01,  3.5872e-01,  1.2314e+00, -4.6212e-01,  6.2421e-01,\n",
      "         -2.6311e+00, -3.0408e+00,  1.2687e+00, -2.8604e+00,  1.1996e+00],\n",
      "        [ 3.1219e+00, -1.5870e+00, -1.3408e+00, -2.5005e+00, -9.2299e-01,\n",
      "         -3.5861e+00,  2.0631e+00,  1.5022e-01, -1.7328e+00,  2.1144e+00,\n",
      "         -6.9247e-01,  1.8848e+00,  2.0342e+00,  7.0171e-01, -1.4003e+00,\n",
      "         -2.1537e+00,  1.1346e+00, -1.1705e+00,  6.4076e-01, -3.6771e+00],\n",
      "        [-9.0377e-01, -4.9029e+00, -2.0482e+00, -7.1058e-01,  2.1898e+00,\n",
      "         -7.0330e+00, -2.9780e+00,  7.4366e-01, -1.5458e+00, -3.9361e-02,\n",
      "          1.0354e+00,  6.1796e-01,  3.1205e+00, -6.3452e-01,  2.3884e+00,\n",
      "         -2.8661e-03,  4.2806e-01,  1.7495e-01,  1.1351e+00, -2.2035e+00],\n",
      "        [-1.6632e+00,  2.0416e+00,  7.4348e-01, -4.3742e-01,  3.7842e+00,\n",
      "         -2.3344e+00,  7.3183e-01,  2.2011e+00,  1.1386e+00, -1.0909e+00,\n",
      "          1.8747e+00,  1.5382e+00, -3.3728e+00, -1.1541e+00, -2.0596e+00,\n",
      "          1.6742e+00,  8.9332e-01, -7.0773e-01,  2.7142e+00,  2.9281e+00],\n",
      "        [-2.0134e+00,  2.3158e-01, -6.9394e-01, -1.0323e+00,  1.1230e-01,\n",
      "          1.7024e+00,  3.5462e+00,  2.6206e+00, -2.1450e+00, -1.0863e+00,\n",
      "         -1.7550e-01,  3.6872e+00,  6.1193e-01, -4.3180e-01, -1.6039e-01,\n",
      "         -2.2903e+00, -2.9360e+00, -1.1531e+00, -1.1627e+00, -6.6195e-01],\n",
      "        [-1.6738e+00, -1.9186e-01, -1.8475e+00, -6.6353e-01,  7.4728e-01,\n",
      "          2.8546e-01, -3.0416e-01, -7.7683e-01, -9.1699e-01, -1.6887e+00,\n",
      "          2.5517e+00, -2.6584e+00,  2.5891e+00, -3.9078e+00, -8.4134e-01,\n",
      "          8.7597e-01,  4.5134e+00,  8.1281e-01,  1.1322e+00, -4.1943e+00],\n",
      "        [ 2.4724e+00,  4.8270e-01,  2.8621e-02, -8.1736e-01, -9.5704e-02,\n",
      "          2.7491e+00, -5.9452e-02,  2.6560e+00,  1.7332e+00, -1.4862e+00,\n",
      "          1.2202e+00, -9.2986e-02,  2.6376e+00, -1.3719e+00,  2.2106e+00,\n",
      "          2.8139e+00, -1.8605e+00,  2.0964e+00, -1.2222e+00, -5.4255e-01],\n",
      "        [-7.6242e-01, -1.9093e+00, -7.9172e-01,  6.4489e-01,  1.4844e-01,\n",
      "         -2.0065e-02, -2.9384e-01, -1.0596e+00, -8.0744e-01,  7.2050e-01,\n",
      "          1.7966e+00, -1.2762e+00,  4.6770e+00, -2.6221e+00, -1.7575e+00,\n",
      "         -9.2905e-02,  1.4292e+00, -1.3161e+00, -9.2386e-01, -4.7064e+00],\n",
      "        [-2.1998e-01,  1.7513e+00,  2.3857e-01, -4.3249e-01,  5.1691e+00,\n",
      "          1.1071e+00,  3.8305e-01,  1.6881e+00,  1.7158e+00, -6.4384e-01,\n",
      "         -2.0502e+00,  2.4736e+00, -8.1787e-02,  7.5540e-01, -3.4210e-01,\n",
      "         -3.4909e+00, -1.9964e+00,  4.9521e+00, -1.1497e+00, -2.3259e-01],\n",
      "        [ 2.1323e+00, -1.0678e+00, -7.2673e-01, -9.5811e-01, -3.3698e+00,\n",
      "         -5.6532e-01, -2.0393e+00,  1.9792e+00, -4.1860e+00,  1.5907e+00,\n",
      "          8.2026e-01,  1.0646e+00,  4.6669e+00,  4.5010e+00,  2.2566e+00,\n",
      "         -8.5873e-01,  1.9446e+00,  4.6115e+00,  5.3777e-01,  1.5638e+00],\n",
      "        [ 4.0034e-01, -2.9679e+00, -1.8624e+00, -3.9570e-01,  3.0238e+00,\n",
      "         -9.2046e-01, -1.8380e+00,  2.4550e+00, -2.6335e+00,  6.6181e-01,\n",
      "          2.2976e+00,  2.8137e+00,  3.9825e-01, -1.1766e+00,  4.0567e+00,\n",
      "          1.3898e+00, -1.8928e+00,  4.1411e-02,  1.4056e+00,  2.2396e+00],\n",
      "        [-2.2733e+00, -4.8479e+00,  1.8568e+00, -6.5953e-01,  4.5441e-02,\n",
      "          1.4647e+00, -2.4729e+00,  8.8621e-01, -5.1811e+00, -1.3190e+00,\n",
      "         -5.1158e-01,  3.9883e+00, -1.4659e+00, -5.0019e-01, -1.0211e+00,\n",
      "          1.5355e+00,  1.2570e+00,  6.7756e-02,  4.9518e-01, -1.0715e+00]])\n",
      "torch.Size([20, 20])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn((20,20), requires_grad=True)\n",
    "fn = torch.trace(X.T @ X)\n",
    "X.grad = None\n",
    "print(X.grad) # dumb check\n",
    "fn.backward()\n",
    "print(X.grad)\n",
    "print(X.grad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am currently not aware of a situation where this would not work. Will return to this section if such an example pops up in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
